= Day-2 Operations

Over time, models deployed in production environments can experience a decrease in performance due to several factors. The most common causes are data drift and concept drift.

* Data Drift occurs when the distribution of the input data changes over time. This means that the data the model is receiving at inference time is different from the data it was trained on. For example, in a factory setting, if the lighting conditions, camera angles, or types of clothing change, the model might not perform as well because it was not exposed to this new kind of data during training.

* Concept Drift happens when the underlying relationships or patterns in the data change. In other words, the target variable that the model is predicting changes its behavior over time. This might happen if the system's goals evolve or if the environment in which the model operates changes. For example, if the factory introduces new policies regarding employee attire, the model might need adjustments to account for those changes.


Retraining your models periodically is a necessary practice to maintain their performance and ensure that they adapt to new conditions. Continuous monitoring and updating of your models are vital to prevent them from becoming obsolete or ineffective due to data and concept drift.


In our example use case, the trained model for detecting hardhats on the factory floor had been deployed and working as expected. However, over time, reports started emerging about incidents where people were not wearing helmets, but the system did not trigger any alarms. After investigation, it was found that the individuals in question were wearing cups or hats, which the model did not recognize as something that could interfere with hardhat detection. Since the model was only trained to detect hardhats and not other headgear, these individuals were simply not detected, causing false negatives.

To solve this issue, retraining the model is necessary. This retraining should include additional objects that could be worn on the head, such as cups or hats. By expanding the dataset to include these new classes of headgear and properly labeling them, the model will be able to differentiate between a person wearing a hardhat, a cup, a hat, or no headgear at all.

The model should also be updated to raise an alarm when a person is either not wearing anything on their head or wearing something that is not a helmet. This update ensures that the system remains relevant and functional in a dynamic, real-world environment where conditions change over time.





== Monitoring

blah, blah









9. Prometheus and Grafana

Overview

Prometheus and Grafana are integral to OpenShift AI’s monitoring stack, providing metrics collection, visualization, and alerting.

Usage with RHEL Inference

Configure Prometheus on RHEL to expose metrics (e.g., inference latency, resource usage).

Forward these metrics to OpenShift AI’s monitoring stack for centralized visualization and analysis in Grafana.












== Dataset Update

blah, blah







== Retraining

blah, blah









== Solution and Next Steps




redeploy ......

